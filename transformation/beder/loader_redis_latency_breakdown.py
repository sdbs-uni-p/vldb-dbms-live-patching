import loader

import hashlib
import multiprocessing
import os
import random
import sys
from argparse import ArgumentParser, Namespace
from concurrent.futures import ProcessPoolExecutor
from functools import reduce
from typing import Callable, List, Optional

import pandas as pd

import data.wf_log_data as wf_log
from data.benchmark_benchmark_data import (
    read_benchbase_benchmark_data,
    read_benchbase_warmup_done_data,
)
from data.benchmark_data import read_benchbase_data
from data.patch_data import read_patch_elf
from data.run_info_data import read_run_info_data
from duckdb_storage import (
    DuckDBStorage,
    DuckDBStorageThread,
    Storage,
    StorageProcessCollector,
)
from future_collector import FutureCollector

def _parse_arguments(input_args: List[str]) -> Namespace:
    parser = ArgumentParser(
        "BEnchmark Data analyzER (BEDER) - a framework to analyze benchmark data based on the data "
        "generated by BenchBase."
    )
    experiment_dir_parser = parser.add_mutually_exclusive_group(required=True)
    experiment_dir_parser.add_argument(
        "--experiment", help="The directory containing the experiment."
    )
    experiment_dir_parser.add_argument(
        "--benchmark", help="The directory containing all the experiment directories."
    )

    parser.add_argument(
        "--output",
        help="The DuckDB database file to which the benchmark data should be added. If the database "
        "file does not exist, a new database file is be created. If the database already exists, "
        "the benchmark data is added.",
        required=True,
        type=str,
    )

    return parser.parse_args(input_args)


def main(input_args: List[str]):
    args = _parse_arguments(input_args)

    m = multiprocessing.Manager()
    db_input_queue = m.JoinableQueue()

    conn: DuckDBStorage
    storage = DuckDBStorageThread(args.output, db_input_queue)
    conn = storage.connect()
    conn.create_tables()

    collector: Storage = StorageProcessCollector(db_input_queue)

    if args.experiment:
        experiments = [args.experiment]
    else:
        experiments = [
            os.path.join(args.benchmark, experiment)
            for experiment in os.listdir(args.benchmark)
            if os.path.isdir(os.path.join(args.benchmark, experiment))
        ]
    experiments = [os.path.realpath(exp) for exp in experiments]

    for experiment in experiments:
        print(experiment)
        for wf_log in [os.path.join(experiment, file) for file in os.listdir(experiment) if "wf_log" in file]:
            print(wf_log)
            *_, patch_global_quiescence, queries = os.path.basename(wf_log).split("_")
            with open(wf_log) as f:
                # [VmPTE 0, 108]
                pte = [line.strip().split(" ")[2][:-1] for line in f.readlines() if "VmPTE" in line][0]
                if int(pte) < 200000:
                    pte = "0.1MB PTE"
                else:
                    pte = "425MB PTE"

            run_hash = hashlib.sha512()
            run_hash.update(f"{random.random()}".encode("UTF-8"))
            run_id = run_hash.hexdigest()
            run_data = pd.DataFrame({"run_id": run_id,
                                     "patch_global_quiescence": [patch_global_quiescence],
                                     "experiment_commit": [os.path.basename(experiment)],
                                     "experiment_name": [pte]})
            storage.insert("run", run_data)
            loader.load_wf_log(storage, wf_log, run_id)

    conn.close()


if __name__ == "__main__":
    main(sys.argv[1:])
